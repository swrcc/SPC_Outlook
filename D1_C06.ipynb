{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5a1268-151d-4c46-9316-ee9d318f19ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1097815/1937867485.py:5: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is already up-to-date.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set the environment variable to use Shapely instead of PyGEOS\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "\n",
    "# Define constants\n",
    "API_URL = 'https://mesonet.agron.iastate.edu/api/1/nws/spc_outlook.geojson'\n",
    "CYCLE = 6  # Change this back to 16 if needed\n",
    "THRESHOLD_LEVELS = ['MRGL', 'SLGT', 'ENH', 'MDT', 'HIGH']\n",
    "MAX_ATTEMPTS = 3\n",
    "\n",
    "# Load NYS boundary shapefile and reproject if necessary\n",
    "nys_boundary_path = '/nfs/home11/ugrad/2020/tr588861/SWRCC/State_Shapefiles/state/State.shp'\n",
    "zip_population_path = '/nfs/home11/ugrad/2020/tr588861/SWRCC/State_Shapefiles/zip_codes/zip_population.shp'\n",
    "\n",
    "nys_boundary = gpd.read_file(nys_boundary_path)\n",
    "nys_boundary.to_crs(epsg=4326, inplace=True)  # Reproject to WGS84 if needed\n",
    "nys_boundary_union = unary_union(nys_boundary.geometry)\n",
    "\n",
    "zip_population = gpd.read_file(zip_population_path)\n",
    "\n",
    "# Calculate the total area and population of New York State\n",
    "total_area = nys_boundary_union.area * (111 ** 2)  # Total area in square kilometers\n",
    "total_population = zip_population['Population'].sum()\n",
    "\n",
    "# Function to fetch and process data for the given date\n",
    "def fetch_and_process_data(date):\n",
    "    params = {\n",
    "        'day': 1,\n",
    "        'valid': date.strftime('%Y-%m-%dT00:00'),\n",
    "        'cycle': CYCLE,\n",
    "        'outlook_type': 'C'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(API_URL, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Dictionary to track the highest threshold level for each zip code\n",
    "    zip_highest_threshold = {}\n",
    "    \n",
    "    # Dictionary to store the area sum under each threshold level\n",
    "    threshold_areas = {level: 0 for level in THRESHOLD_LEVELS}\n",
    "    threshold_polygons = {level: [] for level in THRESHOLD_LEVELS}\n",
    "\n",
    "    for feature in data['features']:\n",
    "        properties = feature['properties']\n",
    "        geometry = feature['geometry']\n",
    "        \n",
    "        if properties['category'] == 'CATEGORICAL':\n",
    "            threshold = properties['threshold']\n",
    "            \n",
    "            if threshold not in THRESHOLD_LEVELS:\n",
    "                continue\n",
    "\n",
    "            # Convert the geometry to a Shapely object (handling MultiPolygon)\n",
    "            polygons = shape(geometry)\n",
    "            if isinstance(polygons, Polygon):\n",
    "                polygons = [polygons]\n",
    "            elif isinstance(polygons, MultiPolygon):\n",
    "                polygons = list(polygons.geoms)\n",
    "\n",
    "            for polygon in polygons:\n",
    "                if polygon.is_valid and polygon.intersects(nys_boundary_union):\n",
    "                    # Calculate the intersection with NYS boundary\n",
    "                    intersection = polygon.intersection(nys_boundary_union)\n",
    "                    \n",
    "                    if intersection.is_empty:\n",
    "                        continue\n",
    "                    \n",
    "                    # Add intersection polygon to the list for the current threshold\n",
    "                    threshold_polygons[threshold].append(intersection)\n",
    "                    \n",
    "                    # Check which zip codes intersect with the intersection polygon\n",
    "                    for idx, zip_geom in zip_population.iterrows():\n",
    "                        if zip_geom.geometry.intersects(intersection):\n",
    "                            zip_code = zip_geom['ZCTA5CE10']  # Assuming the column name for zip code\n",
    "                            current_level_index = THRESHOLD_LEVELS.index(threshold)\n",
    "                            \n",
    "                            # Update the highest threshold level for this zip code\n",
    "                            if zip_code in zip_highest_threshold:\n",
    "                                previous_level_index = THRESHOLD_LEVELS.index(zip_highest_threshold[zip_code])\n",
    "                                if current_level_index < previous_level_index:\n",
    "                                    zip_highest_threshold[zip_code] = threshold\n",
    "                            else:\n",
    "                                zip_highest_threshold[zip_code] = threshold\n",
    "\n",
    "    # Combine polygons for each threshold level and calculate areas\n",
    "    for level in THRESHOLD_LEVELS:\n",
    "        if threshold_polygons[level]:\n",
    "            combined_polygons = unary_union(threshold_polygons[level])\n",
    "            threshold_areas[level] = combined_polygons.area * (111 ** 2)  # Area in square kilometers\n",
    "    \n",
    "    # Initialize a dictionary to store the population sum under each threshold level\n",
    "    population_sum = {level: 0 for level in THRESHOLD_LEVELS}\n",
    "\n",
    "    # Sum the population based on the highest threshold level assigned\n",
    "    for zip_code, highest_level in zip_highest_threshold.items():\n",
    "        highest_index = THRESHOLD_LEVELS.index(highest_level)\n",
    "        population = zip_population.loc[zip_population['ZCTA5CE10'] == zip_code, 'Population'].sum()\n",
    "        for level in THRESHOLD_LEVELS[:highest_index + 1]:\n",
    "            population_sum[level] += population\n",
    "    \n",
    "    # Aggregate area to include higher levels\n",
    "    for i in range(len(THRESHOLD_LEVELS) - 1, 0, -1):\n",
    "        threshold_areas[THRESHOLD_LEVELS[i - 1]] += threshold_areas[THRESHOLD_LEVELS[i]]\n",
    "\n",
    "    return threshold_areas, population_sum, data\n",
    "\n",
    "# Function to handle retries\n",
    "def fetch_with_retries(date, max_attempts=MAX_ATTEMPTS):\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            return fetch_and_process_data(date)\n",
    "        except (requests.ConnectionError, requests.Timeout) as e:\n",
    "            attempts += 1\n",
    "            print(f\"Attempt {attempts} failed for {date.strftime('%Y-%m-%d')}: {e}\")\n",
    "            if attempts == max_attempts:\n",
    "                print(f\"Skipping date {date.strftime('%Y-%m-%d')} after {attempts} failed attempts.\")\n",
    "                return None, None, None\n",
    "\n",
    "# Initialize dictionaries to accumulate data for each hazard level\n",
    "all_data = {level: [] for level in THRESHOLD_LEVELS}\n",
    "\n",
    "# Define the output directory for Cycle 6 data\n",
    "output_dir = '/nfs/home11/ugrad/2020/tr588861/SWRCC/spc_reports/Outlook_Data/Day1/Categorical/D1_C06_Results'\n",
    "\n",
    "# Find the last processed date from MRGL CSV\n",
    "last_processed_date = None\n",
    "marginal_csv_path = os.path.join(output_dir, 'MRGL_data.csv')\n",
    "\n",
    "if os.path.exists(marginal_csv_path):\n",
    "    df = pd.read_csv(marginal_csv_path)\n",
    "    last_processed_date = df['Date'].max()\n",
    "    last_processed_date = datetime.strptime(last_processed_date, '%Y-%m-%d')\n",
    "\n",
    "if last_processed_date and last_processed_date.date() >= datetime.today().date():\n",
    "    print(\"Data is already up-to-date.\")\n",
    "else:\n",
    "    if last_processed_date:\n",
    "        start_date = last_processed_date + timedelta(days=1)\n",
    "    else:\n",
    "        start_date = datetime(2015, 1, 1)\n",
    "\n",
    "    end_date = datetime.today()\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        # Fetch and process data for the current date\n",
    "        threshold_areas, population_data, data = fetch_with_retries(current_date)\n",
    "        \n",
    "        if threshold_areas is not None and population_data is not None:\n",
    "            # Calculate percentages\n",
    "            area_percentages = {level: (threshold_areas[level] / total_area) * 100 for level in THRESHOLD_LEVELS}\n",
    "            population_percentages = {level: (population_data[level] / total_population) * 100 for level in THRESHOLD_LEVELS}\n",
    "            \n",
    "            # Combine area, population, and percentage data into a single table\n",
    "            for level in THRESHOLD_LEVELS:\n",
    "                if threshold_areas[level] > 0 and population_data[level] > 0:\n",
    "                    all_data[level].append([\n",
    "                        level,\n",
    "                        current_date.strftime('%Y-%m-%d'),\n",
    "                        threshold_areas[level],\n",
    "                        area_percentages[level],\n",
    "                        population_data[level],\n",
    "                        population_percentages[level]\n",
    "                    ])\n",
    "        \n",
    "        # Move to the next date\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # Write the accumulated data to CSV files\n",
    "    for level in THRESHOLD_LEVELS:\n",
    "        filepath = os.path.join(output_dir, f'{level}_data.csv')\n",
    "        df = pd.DataFrame(all_data[level], columns=[\n",
    "            'Threshold_Level', 'Date', 'Area_km2', 'Area_Percentage', 'Population', 'Population_Percentage'\n",
    "        ])\n",
    "        if os.path.exists(filepath):\n",
    "            # If file exists, append the new data\n",
    "            df.to_csv(filepath, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            # If file does not exist, create it and write the data with header\n",
    "            df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb46f0e-a725-429a-af62-42ce0a2fd306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 August 2023 Environment",
   "language": "python",
   "name": "aug23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
